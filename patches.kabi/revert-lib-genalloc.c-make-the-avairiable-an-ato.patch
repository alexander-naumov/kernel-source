From: Jiri Slaby <jslaby@suse.cz>
Date: Thu, 4 Jan 2018 21:09:31 +0100
Subject: Revert "lib/genalloc.c: make the avail variable an atomic_long_t"
Patch-mainline: never, kabi
References: kabi

This reverts commit 24c98ec494c2df1e449c6aa6c3904d7c32c20c44, upstream
commit 36a3d1dd4e16bcd0d2ddfb4a2ec7092f0ae0d931. It changes the type of
avail inside struct gen_pool_chunk which break kABI. And the structure
can be used by external modules via gen_pool_for_each_chunk.

Signed-off-by: Jiri Slaby <jslaby@suse.cz>
---
 include/linux/genalloc.h |  3 +--
 lib/genalloc.c           | 10 +++++-----
 2 files changed, 6 insertions(+), 7 deletions(-)

diff --git a/include/linux/genalloc.h b/include/linux/genalloc.h
index 46156ff5b01d..7ff168d06967 100644
--- a/include/linux/genalloc.h
+++ b/include/linux/genalloc.h
@@ -31,7 +31,6 @@
 #define __GENALLOC_H__
 
 #include <linux/spinlock_types.h>
-#include <linux/atomic.h>
 
 struct device;
 struct device_node;
@@ -69,7 +68,7 @@ struct gen_pool {
  */
 struct gen_pool_chunk {
 	struct list_head next_chunk;	/* next chunk in pool */
-	atomic_long_t avail;
+	atomic_t avail;
 	phys_addr_t phys_addr;		/* physical starting address of memory chunk */
 	unsigned long start_addr;	/* start address of memory chunk */
 	unsigned long end_addr;		/* end address of memory chunk (inclusive) */
diff --git a/lib/genalloc.c b/lib/genalloc.c
index e4303fb2a7b2..27aa9c629d13 100644
--- a/lib/genalloc.c
+++ b/lib/genalloc.c
@@ -194,7 +194,7 @@ int gen_pool_add_virt(struct gen_pool *pool, unsigned long virt, phys_addr_t phy
 	chunk->phys_addr = phys;
 	chunk->start_addr = virt;
 	chunk->end_addr = virt + size - 1;
-	atomic_long_set(&chunk->avail, size);
+	atomic_set(&chunk->avail, size);
 
 	spin_lock(&pool->lock);
 	list_add_rcu(&chunk->next_chunk, &pool->chunks);
@@ -285,7 +285,7 @@ unsigned long gen_pool_alloc(struct gen_pool *pool, size_t size)
 	nbits = (size + (1UL << order) - 1) >> order;
 	rcu_read_lock();
 	list_for_each_entry_rcu(chunk, &pool->chunks, next_chunk) {
-		if (size > atomic_long_read(&chunk->avail))
+		if (size > atomic_read(&chunk->avail))
 			continue;
 
 		start_bit = 0;
@@ -305,7 +305,7 @@ retry:
 
 		addr = chunk->start_addr + ((unsigned long)start_bit << order);
 		size = nbits << order;
-		atomic_long_sub(size, &chunk->avail);
+		atomic_sub(size, &chunk->avail);
 		break;
 	}
 	rcu_read_unlock();
@@ -371,7 +371,7 @@ void gen_pool_free(struct gen_pool *pool, unsigned long addr, size_t size)
 			remain = bitmap_clear_ll(chunk->bits, start_bit, nbits);
 			BUG_ON(remain);
 			size = nbits << order;
-			atomic_long_add(size, &chunk->avail);
+			atomic_add(size, &chunk->avail);
 			rcu_read_unlock();
 			return;
 		}
@@ -445,7 +445,7 @@ size_t gen_pool_avail(struct gen_pool *pool)
 
 	rcu_read_lock();
 	list_for_each_entry_rcu(chunk, &pool->chunks, next_chunk)
-		avail += atomic_long_read(&chunk->avail);
+		avail += atomic_read(&chunk->avail);
 	rcu_read_unlock();
 	return avail;
 }
-- 
2.15.1

